{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMEANS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "\n",
    "# Load course embeddings from JSON\n",
    "def load_embeddings(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Load embeddings\n",
    "embedding_file = \"./data/with_sents/course_embed_pos_sent.json\"\n",
    "course_data = load_embeddings(embedding_file)\n",
    "\n",
    "# Extract course codes and their embeddings\n",
    "course_codes = [course[\"course_code\"] for course in course_data]\n",
    "course_embeddings = np.array([course[\"embedding\"] for course in course_data])\n",
    "\n",
    "# Step 1: Standardize the course embeddings\n",
    "scaler = StandardScaler()\n",
    "course_embeddings_scaled = scaler.fit_transform(course_embeddings)\n",
    "\n",
    "# Step 2: Select one course as the initial centroid for each cluster\n",
    "n_clusters = 5  # Number of clusters\n",
    "initial_centroids = course_embeddings_scaled[:n_clusters]  # Take first N course embeddings as initial centroids\n",
    "\n",
    "# Step 3: Perform K-means clustering with predefined initial centroids\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=initial_centroids, n_init=1, random_state=42)\n",
    "kmeans.fit(course_embeddings_scaled)\n",
    "\n",
    "# Step 4: Get the cluster labels and centroids\n",
    "cluster_labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Step 5: Ensure centroids correspond to course embeddings by assigning the closest course to each centroid\n",
    "closest_courses = []\n",
    "for centroid in centroids:\n",
    "    distances = np.linalg.norm(course_embeddings_scaled - centroid, axis=1)  # Calculate the Euclidean distance from centroid to each course\n",
    "    closest_course_idx = np.argmin(distances)  # Find the index of the closest course\n",
    "    closest_courses.append(course_codes[closest_course_idx])  # Store the course code of the closest course\n",
    "\n",
    "# Step 6: Add the cluster labels and centroid course codes to the course data\n",
    "course_clusters = pd.DataFrame({\n",
    "    'Course Code': course_codes,\n",
    "    'Cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# Add a new column \"Centroid course code\" with the closest course code for each cluster\n",
    "course_clusters['Centroid course code'] = [closest_courses[label] for label in course_clusters['Cluster']]\n",
    "\n",
    "# Step 7: Print the course clusters DataFrame\n",
    "#print(course_clusters)\n",
    "course_clusters.to_json(\"./data/with_sents/course_clusters.json\", orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athina/Desktop/HackTheBurgh/htb_venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar centroids to your query:\n",
      "Course Code: INFR11223, Similarity Score: 0.2442\n",
      "Course Code: INFR10086, Similarity Score: 0.1974\n",
      "Course Code: INFR08025, Similarity Score: 0.0637\n",
      "Course Code: INFR11244, Similarity Score: 0.0545\n",
      "Course Code: INFR11077, Similarity Score: 0.0082\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to embed user query\n",
    "def embed_query(query, model):\n",
    "    return model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "# Load course cluster data (from a JSON file format similar to the one you provided)\n",
    "def load_cluster_data(file_path):\n",
    "    centroids = set()  # To keep track of unique centroid course codes\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cluster_data = json.loads(line.strip())  # Each line is a JSON object\n",
    "            centroids.add(cluster_data[\"Centroid course code\"])\n",
    "    return list(centroids)  # Return the unique centroids as a list\n",
    "\n",
    "# Load course embeddings (from a JSON file format similar to the one you provided)\n",
    "def load_embeddings(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Extract the embeddings for the unique centroids\n",
    "def get_centroid_embeddings(cluster_file_path, embedding_file_path):\n",
    "    # Load cluster data to get the unique centroid course codes\n",
    "    centroid_courses = load_cluster_data(cluster_file_path)\n",
    "    \n",
    "    # Load course embeddings\n",
    "    embeddings_data = load_embeddings(embedding_file_path)\n",
    "    \n",
    "    # Create a dictionary to store the centroid course code and corresponding embeddings\n",
    "    centroids_embeddings = {}\n",
    "    \n",
    "    # Map embeddings to centroid course codes\n",
    "    for course in embeddings_data:\n",
    "        if course[\"course_code\"] in centroid_courses:\n",
    "            centroids_embeddings[course[\"course_code\"]] = course[\"embedding\"]\n",
    "    \n",
    "    return centroids_embeddings\n",
    "\n",
    "\n",
    "# Get the embeddings of the cluster centroids\n",
    "cluster_file = \"data/with_sents/course_clusters.json\"\n",
    "embedding_file = \"data/with_sents/course_embed_pos_sent.json\"\n",
    "centroid_embeddings = get_centroid_embeddings(cluster_file, embedding_file)\n",
    "\n",
    "# Initialize embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Get the user query\n",
    "user_query = input(\"Enter your query: \")  # Example: \"Machine Learning and AI\"\n",
    "query_embedding = embed_query(user_query, model)\n",
    "\n",
    "# Step 1: Compute cosine similarity between the query embedding and all centroid embeddings\n",
    "centroid_embeddings_array = list(centroid_embeddings.values())  # Extract the list of centroid embeddings\n",
    "centroid_course_codes = list(centroid_embeddings.keys())  # Corresponding course codes of centroids\n",
    "\n",
    "# Compute cosine similarity (query_embedding should be compared to each centroid embedding)\n",
    "similarity_scores = cosine_similarity([query_embedding], centroid_embeddings_array)[0]\n",
    "\n",
    "# Step 2: Get the top k most similar centroids\n",
    "k = 5  # Define the number of top centroids you want\n",
    "top_k_indices = np.argsort(similarity_scores)[-k:][::-1]  # Indices of the top k highest similarity scores\n",
    "\n",
    "# Step 3: Print the top k most similar centroids along with their similarity scores\n",
    "print(f\"Top {k} most similar centroids to your query:\")\n",
    "for idx in top_k_indices:\n",
    "    course_code = centroid_course_codes[idx]\n",
    "    score = similarity_scores[idx]\n",
    "    print(f\"Course Code: {course_code}, Similarity Score: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('htb_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22bb2fc85997b4f47b9ae1aa55adbbf2dc4038ec965551eb831f4589c072d8a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
