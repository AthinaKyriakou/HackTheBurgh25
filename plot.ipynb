{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMEANS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "\n",
    "# Load course embeddings from JSON\n",
    "def load_embeddings(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Load embeddings\n",
    "embedding_file = \"./data/with_sents/course_embed_pos_sent.json\"\n",
    "course_data = load_embeddings(embedding_file)\n",
    "\n",
    "# Extract course codes and their embeddings\n",
    "course_codes = [course[\"course_code\"] for course in course_data]\n",
    "course_embeddings = np.array([course[\"embedding\"] for course in course_data])\n",
    "\n",
    "# Step 1: Standardize the course embeddings\n",
    "scaler = StandardScaler()\n",
    "course_embeddings_scaled = scaler.fit_transform(course_embeddings)\n",
    "\n",
    "# Step 2: Select one course as the initial centroid for each cluster\n",
    "n_clusters = 20  # Number of clusters\n",
    "initial_centroids = course_embeddings_scaled[:n_clusters]  # Take first N course embeddings as initial centroids\n",
    "\n",
    "# Step 3: Perform K-means clustering with predefined initial centroids\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=initial_centroids, n_init=1, random_state=42)\n",
    "kmeans.fit(course_embeddings_scaled)\n",
    "\n",
    "# Step 4: Get the cluster labels and centroids\n",
    "cluster_labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Step 5: Ensure centroids correspond to course embeddings by assigning the closest course to each centroid\n",
    "closest_courses = []\n",
    "for centroid in centroids:\n",
    "    distances = np.linalg.norm(course_embeddings_scaled - centroid, axis=1)  # Calculate the Euclidean distance from centroid to each course\n",
    "    closest_course_idx = np.argmin(distances)  # Find the index of the closest course\n",
    "    closest_courses.append(course_codes[closest_course_idx])  # Store the course code of the closest course\n",
    "\n",
    "# Step 6: Add the cluster labels and centroid course codes to the course data\n",
    "course_clusters = pd.DataFrame({\n",
    "    'Course Code': course_codes,\n",
    "    'Cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# Add a new column \"Centroid course code\" with the closest course code for each cluster\n",
    "course_clusters['Centroid course code'] = [closest_courses[label] for label in course_clusters['Cluster']]\n",
    "\n",
    "# Step 7: Print the course clusters DataFrame\n",
    "#print(course_clusters)\n",
    "course_clusters.to_json(\"./data/with_sents/course_clusters.json\", orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 most similar centroids to your query:\n",
      "\n",
      "Centroid Course Code: INFR10061, Similarity Score: 0.4037\n",
      "  Cluster Courses: INFR08025, INFR10065, INFR10061, INFR11023, INFR11114\n",
      "\n",
      "Centroid Course Code: INFR08020, Similarity Score: 0.3950\n",
      "  Cluster Courses: INFR08020, INFR10078, INFR11125, INFR11033, INFR11209, INFR11212, INFR11194, INFR11140, INFR11157, INFR11210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to embed user query\n",
    "def embed_query(query, model):\n",
    "    return model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "# Load course cluster data (from a JSON file format similar to the one you provided)\n",
    "def load_cluster_data(file_path):\n",
    "    clusters = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cluster_data = json.loads(line.strip())  # Each line is a JSON object\n",
    "            cluster_code = cluster_data[\"Cluster\"]\n",
    "            course_code = cluster_data[\"Course Code\"]\n",
    "            centroid_code = cluster_data[\"Centroid course code\"]\n",
    "\n",
    "            # Group courses by their cluster\n",
    "            if cluster_code not in clusters:\n",
    "                clusters[cluster_code] = {\"centroid\": centroid_code, \"courses\": []}\n",
    "            clusters[cluster_code][\"courses\"].append(course_code)\n",
    "    \n",
    "    return clusters  # Return the clusters with courses and centroid information\n",
    "\n",
    "# Load course embeddings (from a JSON file format similar to the one you provided)\n",
    "def load_embeddings(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Extract the embeddings for the unique centroids\n",
    "def get_centroid_embeddings(cluster_file_path, embedding_file_path):\n",
    "    clusters = load_cluster_data(cluster_file_path)\n",
    "    \n",
    "    # Load course embeddings\n",
    "    embeddings_data = load_embeddings(embedding_file_path)\n",
    "    \n",
    "    # Create a dictionary to store the centroid course code and corresponding embeddings\n",
    "    centroids_embeddings = {}\n",
    "    \n",
    "    # Map embeddings to centroid course codes\n",
    "    for course in embeddings_data:\n",
    "        if course[\"course_code\"] in [cluster[\"centroid\"] for cluster in clusters.values()]:\n",
    "            centroids_embeddings[course[\"course_code\"]] = course[\"embedding\"]\n",
    "    \n",
    "    return centroids_embeddings, clusters\n",
    "\n",
    "\n",
    "# Get the embeddings of the cluster centroids and cluster info\n",
    "cluster_file = \"data/with_sents/course_clusters.json\"\n",
    "embedding_file = \"data/with_sents/course_embed_pos_sent.json\"\n",
    "centroid_embeddings, clusters = get_centroid_embeddings(cluster_file, embedding_file)\n",
    "\n",
    "# Initialize embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Get the user query\n",
    "user_query = input(\"Enter your query: \")  # Example: \"Machine Learning and AI\"\n",
    "query_embedding = embed_query(user_query, model)\n",
    "\n",
    "# Step 1: Compute cosine similarity between the query embedding and all centroid embeddings\n",
    "centroid_embeddings_array = list(centroid_embeddings.values())  # Extract the list of centroid embeddings\n",
    "centroid_course_codes = list(centroid_embeddings.keys())  # Corresponding course codes of centroids\n",
    "\n",
    "# Compute cosine similarity (query_embedding should be compared to each centroid embedding)\n",
    "similarity_scores = cosine_similarity([query_embedding], centroid_embeddings_array)[0]\n",
    "\n",
    "# Step 2: Get the top 2 most similar centroids\n",
    "k = 2  # We only want the top 2 similar centroids\n",
    "top_k_indices = np.argsort(similarity_scores)[-k:][::-1]  # Indices of the top k highest similarity scores\n",
    "\n",
    "# Step 3: Print the courses corresponding to the clusters of the top 2 most similar centroids\n",
    "print(f\"Top {k} most similar centroids to your query:\")\n",
    "\n",
    "# Print the courses of the top 2 clusters\n",
    "for idx in top_k_indices:\n",
    "    course_code = centroid_course_codes[idx]\n",
    "    score = similarity_scores[idx]\n",
    "    print(f\"\\nCentroid Course Code: {course_code}, Similarity Score: {score:.4f}\")\n",
    "    \n",
    "    # Find the cluster for this centroid and print its courses\n",
    "    for cluster_code, cluster_data in clusters.items():\n",
    "        if cluster_data[\"centroid\"] == course_code:\n",
    "            print(f\"  Cluster Courses: {', '.join(cluster_data['courses'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most similar courses to your query:\n",
      "Course Code: INFR10078, Similarity Score: 0.2877\n",
      "Course Code: INFR11157, Similarity Score: 0.2810\n",
      "Course Code: INFR11125, Similarity Score: 0.2726\n",
      "Course Code: INFR11194, Similarity Score: 0.2566\n",
      "Course Code: INFR08020, Similarity Score: 0.1062\n",
      "Course Code: INFR09032, Similarity Score: 0.0695\n",
      "Course Code: INFR11017, Similarity Score: 0.0583\n",
      "Course Code: INFR11033, Similarity Score: 0.0580\n",
      "Course Code: INFR11210, Similarity Score: 0.0007\n",
      "Course Code: INFR11209, Similarity Score: -0.0130\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to embed user query\n",
    "def embed_query(query, model):\n",
    "    return model.encode(query, convert_to_numpy=True)\n",
    "\n",
    "# Load course cluster data (from a JSON file format similar to the one you provided)\n",
    "def load_cluster_data(file_path):\n",
    "    clusters = {}\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cluster_data = json.loads(line.strip())  # Each line is a JSON object\n",
    "            cluster_code = cluster_data[\"Cluster\"]\n",
    "            course_code = cluster_data[\"Course Code\"]\n",
    "            centroid_code = cluster_data[\"Centroid course code\"]\n",
    "\n",
    "            # Group courses by their cluster\n",
    "            if cluster_code not in clusters:\n",
    "                clusters[cluster_code] = {\"centroid\": centroid_code, \"courses\": []}\n",
    "            clusters[cluster_code][\"courses\"].append(course_code)\n",
    "    \n",
    "    return clusters  # Return the clusters with courses and centroid information\n",
    "\n",
    "# Load course embeddings (from a JSON file format similar to the one you provided)\n",
    "def load_embeddings(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Extract the embeddings for the unique centroids\n",
    "def get_centroid_embeddings(cluster_file_path, embedding_file_path):\n",
    "    clusters = load_cluster_data(cluster_file_path)\n",
    "    \n",
    "    # Load course embeddings\n",
    "    embeddings_data = load_embeddings(embedding_file_path)\n",
    "    \n",
    "    # Create a dictionary to store the centroid course code and corresponding embeddings\n",
    "    centroids_embeddings = {}\n",
    "    \n",
    "    # Map embeddings to centroid course codes\n",
    "    for course in embeddings_data:\n",
    "        if course[\"course_code\"] in [cluster[\"centroid\"] for cluster in clusters.values()]:\n",
    "            centroids_embeddings[course[\"course_code\"]] = course[\"embedding\"]\n",
    "    \n",
    "    return centroids_embeddings, clusters\n",
    "\n",
    "\n",
    "# Get the embeddings of the cluster centroids and cluster info\n",
    "cluster_file = \"data/with_sents/course_clusters.json\"\n",
    "embedding_file = \"data/with_sents/course_embed_pos_sent.json\"\n",
    "centroid_embeddings, clusters = get_centroid_embeddings(cluster_file, embedding_file)\n",
    "\n",
    "# Initialize embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Get the user query\n",
    "user_query = input(\"Enter your query: \")  # Example: \"Machine Learning and AI\"\n",
    "query_embedding = embed_query(user_query, model)\n",
    "\n",
    "user_query = input(\"Enter your query: \")  # Example: \"Machine Learning and AI\"\n",
    "query_embedding1 = embed_query('I love Natural Language Processing', model)\n",
    "query_embedding2 = embed_query('I Hate Machine Learning Practica', model)\n",
    "\n",
    "query_embedding = query_embedding1 - query_embedding2\n",
    "\n",
    "\n",
    "# Step 1: Compute cosine similarity between the query embedding and all centroid embeddings\n",
    "centroid_embeddings_array = list(centroid_embeddings.values())  # Extract the list of centroid embeddings\n",
    "centroid_course_codes = list(centroid_embeddings.keys())  # Corresponding course codes of centroids\n",
    "\n",
    "# Compute cosine similarity (query_embedding should be compared to each centroid embedding)\n",
    "similarity_scores = cosine_similarity([query_embedding], centroid_embeddings_array)[0]\n",
    "\n",
    "# Step 2: Get the top 2 most similar centroids\n",
    "k = 2  # We only want the top 2 similar centroids\n",
    "top_k_indices = np.argsort(similarity_scores)[-k:][::-1]  # Indices of the top k highest similarity scores\n",
    "\n",
    "# Step 3: Collect the courses in the top-2 clusters\n",
    "courses_in_top_clusters = []\n",
    "for idx in top_k_indices:\n",
    "    course_code = centroid_course_codes[idx]\n",
    "    \n",
    "    # Find the cluster for this centroid and get its courses\n",
    "    for cluster_code, cluster_data in clusters.items():\n",
    "        if cluster_data[\"centroid\"] == course_code:\n",
    "            courses_in_top_clusters.extend(cluster_data[\"courses\"])\n",
    "\n",
    "# Step 4: Get embeddings for courses in the top-2 clusters\n",
    "courses_embeddings = {course[\"course_code\"]: course[\"embedding\"] for course in load_embeddings(embedding_file) if course[\"course_code\"] in courses_in_top_clusters}\n",
    "\n",
    "# Step 5: Compute cosine similarity between the query_embedding and all course embeddings in the top-2 clusters\n",
    "course_embeddings_array = list(courses_embeddings.values())  # Extract the list of course embeddings\n",
    "course_codes = list(courses_embeddings.keys())  # Corresponding course codes of the courses in the top-2 clusters\n",
    "\n",
    "# Compute cosine similarity (query_embedding should be compared to each course embedding)\n",
    "course_similarity_scores = cosine_similarity([query_embedding], course_embeddings_array)[0]\n",
    "\n",
    "# Step 6: Get the top 10 most similar courses\n",
    "top_10_indices = np.argsort(course_similarity_scores)[-10:][::-1]  # Indices of the top 10 highest similarity scores\n",
    "\n",
    "# Step 7: Print the top 10 most similar courses along with their similarity scores\n",
    "print(f\"\\nTop 10 most similar courses to your query:\")\n",
    "for idx in top_10_indices:\n",
    "    course_code = course_codes[idx]\n",
    "    score = course_similarity_scores[idx]\n",
    "    print(f\"Course Code: {course_code}, Similarity Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('htb_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22bb2fc85997b4f47b9ae1aa55adbbf2dc4038ec965551eb831f4589c072d8a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
